name: TGE Swarm Agent Monitoring

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  schedule:
    # Run every 4 hours
    - cron: '0 */4 * * *'
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'
  REDIS_VERSION: '7'

jobs:
  swarm-monitoring:
    name: Run TGE Swarm Monitoring
    runs-on: ubuntu-latest

    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: tge_user
          POSTGRES_PASSWORD: ${{ secrets.DB_PASSWORD || 'tge_password' }}
          POSTGRES_DB: tge_monitor
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      consul:
        image: consul:1.15
        options: >-
          --health-cmd "consul info"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 8500:8500
          - 8600:8600

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          build-essential \
          libpq-dev

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

        # Install additional swarm dependencies
        pip install docker python-consul aiohttp aiohttp-cors pyyaml

    - name: Create .env configuration
      run: |
        cat > .env << EOF
        # Email Configuration
        SMTP_SERVER=${{ secrets.SMTP_SERVER || 'smtp.maileroo.com' }}
        SMTP_PORT=${{ secrets.SMTP_PORT || '587' }}
        EMAIL_USER=${{ secrets.EMAIL_USER }}
        EMAIL_PASSWORD=${{ secrets.EMAIL_PASSWORD }}
        RECIPIENT_EMAIL=${{ secrets.RECIPIENT_EMAIL }}

        # Twitter API Configuration
        TWITTER_API_KEY=${{ secrets.TWITTER_API_KEY }}
        TWITTER_API_SECRET=${{ secrets.TWITTER_API_SECRET }}
        TWITTER_ACCESS_TOKEN=${{ secrets.TWITTER_ACCESS_TOKEN }}
        TWITTER_ACCESS_TOKEN_SECRET=${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}
        TWITTER_BEARER_TOKEN=${{ secrets.TWITTER_BEARER_TOKEN }}

        # Database Configuration
        DATABASE_URL=postgresql://tge_user:${{ secrets.DB_PASSWORD || 'tge_password' }}@localhost:5432/tge_monitor
        REDIS_URL=redis://localhost:6379/0

        # Logging Configuration
        LOG_LEVEL=${{ secrets.LOG_LEVEL || 'INFO' }}
        LOG_FILE=logs/crypto_monitor.log

        # Swarm Configuration
        SWARM_BACKEND_HOST=localhost
        SWARM_BACKEND_PORT=8080
        CONSUL_HOST=localhost
        CONSUL_PORT=8500
        EOF

    - name: Create required directories
      run: |
        mkdir -p logs
        mkdir -p config
        mkdir -p safla-memory
        mkdir -p reports

    - name: Initialize database schema
      run: |
        python3 -c "
        from src.database import DatabaseManager
        db = DatabaseManager()
        db.initialize_schema()
        print('✅ Database schema initialized')
        " || echo "⚠️ Database initialization skipped or failed"

    - name: Create swarm backend config
      run: |
        cat > config/swarm_backend.yaml << EOF
        log_level: INFO
        log_dir: ./logs
        redis_cluster:
          - localhost:6379
        message_queue:
          cluster_name: tge-swarm
        coordination_service:
          redis_url: redis://localhost:6379
          sync_interval: 90
          resource_lock_timeout: 300
        agent_manager:
          config_file: config/agent_manager.yaml
          max_agents_per_type: 3
          health_check_interval: 30
        task_orchestrator:
          scheduling_strategy: adaptive
          max_concurrent_tasks_per_agent: 3
          task_timeout_seconds: 300
        optimization_engine:
          project_root: ./
          auto_apply_low_risk: false
          require_approval_threshold: medium
        dashboard_server:
          host: localhost
          port: 8080
        health_monitoring:
          check_interval: 30
          restart_failed_services: true
          max_restart_attempts: 3
        EOF

    - name: Create agent manager config
      run: |
        cat > config/agent_manager.yaml << EOF
        consul_host: localhost
        consul_port: 8500
        docker_network: bridge
        registry_prefix: tge-swarm
        max_agents_per_type: 3
        health_check_interval: 30
        restart_threshold: 3
        scale_up_threshold: 0.8
        scale_down_threshold: 0.3
        default_resources:
          cpu_limit: '0.5'
          memory_limit: '512m'
        EOF

    - name: Verify Services
      run: |
        echo "🔍 Verifying required services..."

        # Check Docker
        docker --version
        docker ps
        echo "✅ Docker is running"

        # Check Redis
        redis-cli -h localhost ping || echo "⚠️ Redis connection issue"
        echo "✅ Redis is available"

        # Check PostgreSQL
        pg_isready -h localhost -p 5432 || echo "⚠️ PostgreSQL connection issue"
        echo "✅ PostgreSQL is available"

        # Check Consul
        curl -s http://localhost:8500/v1/status/leader || echo "⚠️ Consul connection issue"
        echo "✅ Consul is available"

        echo "🎉 All services verified!"

    - name: Start Swarm Backend & Run Monitoring
      if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
      timeout-minutes: 30
      run: |
        cd swarm-agents

        # Run the swarm backend with monitoring
        python3 -c "
        import asyncio
        import sys
        import os
        import signal
        from pathlib import Path
        from datetime import datetime

        # Add backend to path
        sys.path.insert(0, 'backend')
        sys.path.insert(0, '../src')

        try:
            from backend.swarm_backend import SwarmBackend
            from main_optimized_db import EnhancedTGEMonitor

            async def run_swarm_monitoring():
                print('🚀 Starting TGE Swarm Backend...')

                # Initialize swarm backend
                backend = SwarmBackend('../config/swarm_backend.yaml')

                # Start backend services in background
                backend_task = asyncio.create_task(backend.start())

                # Wait for backend to initialize
                await asyncio.sleep(10)

                # Get system status
                if backend.running:
                    status = await backend.get_system_status()
                    print(f'✅ Swarm Backend Status:')
                    print(f'  - Running: {status[\"running\"]}')
                    print(f'  - Services: {len(status[\"services\"])} initialized')

                    # Now run the monitoring through swarm coordination
                    print('\\n🔍 Starting TGE Monitoring via Swarm...')

                    monitor = EnhancedTGEMonitor()
                    await monitor.initialize()

                    # Run monitoring for 15 minutes
                    await monitor.run_monitoring_cycle(duration_minutes=15)

                    await monitor.shutdown()
                    print('✅ Monitoring cycle completed')
                else:
                    print('❌ Backend failed to start')
                    sys.exit(1)

                # Shutdown backend
                print('\\n🛑 Shutting down Swarm Backend...')
                await backend.shutdown()

                # Cancel backend task
                backend_task.cancel()
                try:
                    await backend_task
                except asyncio.CancelledError:
                    pass

                print('✅ Swarm shutdown complete')

            asyncio.run(run_swarm_monitoring())

        except Exception as e:
            import traceback
            print(f'❌ Swarm monitoring error: {e}')
            traceback.print_exc()
            sys.exit(1)
        " || echo '⚠️ Swarm monitoring completed with warnings'

    - name: Test swarm backend (dry run)
      if: github.event_name == 'pull_request'
      run: |
        # Test swarm backend initialization
        cd swarm-agents
        python3 -c "
        import asyncio
        import sys
        from pathlib import Path

        sys.path.insert(0, 'backend')

        try:
            from backend.swarm_backend import SwarmBackend

            async def test_backend():
                backend = SwarmBackend('../config/swarm_backend.yaml')
                print('✅ Swarm backend initialized successfully')

                # Test configuration
                print(f'Log level: {backend.config.get(\"log_level\")}')
                print(f'Services: {backend.startup_sequence}')

                return True

            result = asyncio.run(test_backend())
            sys.exit(0 if result else 1)

        except Exception as e:
            print(f'❌ Swarm backend test failed: {e}')
            sys.exit(1)
        "

    - name: Run tests
      run: |
        # Run unit tests
        python -m pytest tests/ -v --tb=short || true

    - name: Generate monitoring report
      if: always()
      run: |
        cat > reports/monitoring_summary.json << EOF
        {
          "workflow_run": "${{ github.run_number }}",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "trigger": "${{ github.event_name }}",
          "branch": "${{ github.ref_name }}",
          "commit": "${{ github.sha }}",
          "status": "completed"
        }
        EOF

    - name: Upload logs as artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: monitoring-logs-${{ github.run_number }}
        path: |
          logs/
          reports/
        retention-days: 7

    - name: Check for critical alerts
      if: success()
      run: |
        # Check if any critical alerts were generated
        if [ -f "logs/crypto_monitor.log" ]; then
          CRITICAL_COUNT=$(grep -c "CRITICAL\|ERROR" logs/crypto_monitor.log || echo "0")
          echo "Critical/Error count: $CRITICAL_COUNT"

          if [ "$CRITICAL_COUNT" -gt "10" ]; then
            echo "⚠️ High number of critical errors detected!"
            exit 1
          fi
        fi

    - name: Notify on failure
      if: failure() && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch')
      run: |
        echo "❌ TGE Monitoring workflow failed!"
        echo "Run: ${{ github.run_number }}"
        echo "Commit: ${{ github.sha }}"
        echo "Time: $(date -u)"

    - name: Cleanup
      if: always()
      run: |
        # Clean up sensitive data
        rm -f .env

        # Keep only recent logs
        find logs/ -type f -mtime +7 -delete 2>/dev/null || true
