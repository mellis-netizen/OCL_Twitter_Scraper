{
  "project": {
    "name": "TGE News Sweeper",
    "type": "Token Generation Event Monitoring & Scraping System",
    "purpose": "Real-time monitoring and scraping of news sources for token launch announcements",
    "critical_components": [
      "News source scrapers (Twitter/X, news sites)",
      "Keyword matching engine",
      "Token launch detection",
      "Company tracking system",
      "Alert/notification system",
      "Data persistence layer"
    ],
    "priority_areas": [
      "Scraping efficiency and rate limiting",
      "Keyword matching accuracy",
      "API reliability and error handling",
      "Data quality and deduplication",
      "Real-time performance",
      "Production-grade error handling",
      "Scalability and resource optimization"
    ]
  },
  "optimization_goals": {
    "performance": [
      "Minimize API calls while maximizing coverage",
      "Optimize concurrent scraping operations",
      "Reduce memory footprint",
      "Implement efficient caching strategies"
    ],
    "reliability": [
      "Production-grade error handling",
      "Rate limit compliance",
      "Graceful degradation",
      "Comprehensive logging",
      "Health monitoring"
    ],
    "accuracy": [
      "Keyword matching precision",
      "False positive reduction",
      "Company name disambiguation",
      "Token symbol detection accuracy"
    ],
    "code_quality": [
      "Clean architecture patterns",
      "Comprehensive test coverage",
      "Documentation completeness",
      "Security best practices",
      "Maintainability"
    ]
  },
  "repository_structure": "",
  "source_files": [
  "./tests/unit/test_circuit_breaker.py",
  "./tests/unit/test_database_models.py",
  "./tests/unit/test_agent_manager.py",
  "./tests/unit/test_message_queue.py",
  "./tests/conftest.py",
  "./tests/integration/test_service_coordination.py",
  "./tests/utils/test_helpers.py",
  "./tests/performance/test_load_and_performance.py",
  "./tests/e2e/test_complete_workflows.py",
  "./deploy-swarm.py",
  "./benchmark_performance.py",
  "./backend/database/models.py",
  "./backend/database/__init__.py",
  "./backend/optimized_message_queue.py",
  "./backend/optimization_engine.py",
  "./backend/swarm_backend.py",
  "./backend/message_queue.py",
  "./backend/resilience/__init__.py",
  "./backend/resilience/retry_handler.py",
  "./backend/resilience/circuit_breaker.py",
  "./backend/coordination_service.py",
  "./backend/agent_manager.py",
  "./backend/task_orchestrator.py",
  "./backend/performance/memory_manager.py",
  "./backend/performance/message_batching.py",
  "./backend/performance/monitoring.py",
  "./backend/performance/async_optimizer.py",
  "./backend/performance/__init__.py",
  "./backend/performance/profiler.py",
  "./backend/performance/connection_pool.py",
  "./backend/websocket_manager.py",
  "./lowest_possible_cost_aws/scripts/cost-optimizer.py",
  "./dashboard/src/types/index.ts",
  "./dashboard-api-server.py",
  "./infrastructure/health/health_monitor.py",
  "./infrastructure/deployment/agent_deployment_framework.py",
  "./swarm_memory_coordinator.py",
  ""
],
  "config_files": [
  "./safla-swarm-config.yaml",
  "./docker-compose.swarm.yml",
  "./lowest_possible_cost_aws/docker/docker-compose-cost-optimized.yml",
  "./dashboard/package.json",
  "./dashboard/tsconfig.json",
  "./dashboard/.env.example",
  "./safla-context.json",
  "./.claude-flow/metrics/agent-metrics.json",
  "./.claude-flow/metrics/task-metrics.json",
  "./.claude-flow/metrics/performance.json",
  "./infrastructure/consul/config/consul.json",
  "./infrastructure/aws/.github/workflows/deploy.yml",
  "./infrastructure/monitoring/grafana/provisioning/datasources/prometheus.yml",
  "./infrastructure/monitoring/grafana/provisioning/dashboards/dashboard.yml",
  "./infrastructure/monitoring/prometheus/rules/swarm_alerts.yml",
  "./infrastructure/monitoring/prometheus/prometheus.yml",
  ""
],
  "tests": [
  "./tests/unit/test_circuit_breaker.py",
  "./tests/unit/test_database_models.py",
  "./tests/unit/test_agent_manager.py",
  "./tests/unit/test_message_queue.py",
  "./tests/conftest.py",
  "./tests/integration/test_service_coordination.py",
  "./tests/utils/test_helpers.py",
  "./tests/performance/test_load_and_performance.py",
  "./tests/e2e/test_complete_workflows.py",
  ""
],
  "documentation": [
  "./TESTING_FRAMEWORK_SUMMARY.md",
  "./CONFIG_INTEGRATION_STATUS.md",
  "./INFRASTRUCTURE_ARCHITECTURE.md",
  "./keyword-analyzer.md",
  "./api-guardian.md",
  "./QUICK_DEPLOY_AWS.md",
  "./AWS_DEPLOYMENT_GUIDE.md",
  "./scraping-specialist.md",
  "./CONFIG_INTEGRATION_GUIDE.md",
  "./backend/README.md",
  "./lowest_possible_cost_aws/docs/COST_OPTIMIZATION_GUIDE.md",
  "./lowest_possible_cost_aws/README.md",
  "./dashboard/README.md",
  "./scraping-efficiency-specialist.md",
  "./OPTIMIZATION_SUMMARY.md",
  "./performance-optimizer.md",
  "./infrastructure/aws/README.md",
  "./tge-keyword-precision-specialist.md",
  "./performance_optimization_report.md",
  "./QUICK_START.md",
  ""
],
  "scraping_targets": {
    "twitter": "Real-time tweet monitoring",
    "news_sites": "RSS feeds, web scraping, APIs",
    "company_sources": "Official channels and announcements"
  },
  "review_focus": [
    "Scraper implementation quality",
    "Rate limiting and API compliance",
    "Keyword matching algorithm effectiveness",
    "Error handling robustness",
    "Data validation and sanitization",
    "Concurrency and async patterns",
    "Resource management",
    "Monitoring and observability"
  ]
}
